{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Fine tuned GPT 3.5**"
      ],
      "metadata": {
        "id": "L8O7Kah54qls"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook demonstrates fine-tuning GPT-3.5 using task-specific method to topic detection. It includes dataset preparation, model training with task-relevant data, evaluation, and loss visualization. Additionally, it showcases generating and streaming predictions with stopping criteria. Ideal for specialized text classification tasks."
      ],
      "metadata": {
        "id": "uDv_oxZ645f7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LLM Task specific training**\n",
        "\n",
        "Training a Large Language Model (LLM) for task-specific training involves fine-tuning the model on a tailored dataset, enabling it to specialize in a particular task or domain. This process enhances the LLM's ability to understand and generate relevant outputs for specific use cases."
      ],
      "metadata": {
        "id": "T_mS8j_s5LoE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task-Relevant Data:**\n",
        "\n",
        "The dataset used for fine-tuning must be directly related to the task you want the model to perform. This data is typically labeled, meaning each example in the dataset includes both input data and the desired output.\n",
        "\n",
        "Examples:\n",
        "\n",
        "Text Classification: A dataset where each piece of text (e.g., a tweet) is labeled with a category (e.g., positive, negative, neutral sentiment).\n",
        "\n",
        "Question Answering: A dataset containing questions and corresponding answers, where the model learns to predict the correct answer given a question."
      ],
      "metadata": {
        "id": "wVhcCXxa5fMo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset generation**"
      ],
      "metadata": {
        "id": "Ro1Y0JQV5yfU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAfstieJ75Np",
        "outputId": "4356f7da-a9b3-4904-e280-0c5444936df1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.5)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.10.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.8.30)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->openai==0.28) (4.12.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"A model that takes in a sentence or text in English, and responds with the detected topic.\"\n",
        "temperature = .4\n",
        "number_of_examples = 100"
      ],
      "metadata": {
        "id": "0QlRptbD51wt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai tenacity"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fRqnjSr6O-4",
        "outputId": "82109d6b-15cc-465c-ccf1-ca2f2f835bd2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.10/dist-packages (9.0.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.10.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2024.8.30)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->openai) (4.12.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Installing required libraries\n",
        "import os\n",
        "import openai\n",
        "import random\n",
        "from tenacity import retry, stop_after_attempt, wait_exponential\n"
      ],
      "metadata": {
        "id": "AgIMl9Jq6V1L"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = \"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\"\n",
        "\n",
        "N_RETRIES = 3\n",
        "\n",
        "#Define the system message for generating topic detection training data\n",
        "@retry(stop=stop_after_attempt(N_RETRIES), wait=wait_exponential(multiplier=1, min=4, max=70))\n",
        "def generate_example(prompt, prev_examples, temperature=.5):\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": f\"You are generating data to train a machine learning model for topic detection.\\n\\nYou will be given a high-level description of the model we want to train, and from that, you will generate data samples, each with a sentence and its corresponding topic.\\n\\nGenerate one example per turn in this format:\\n```\\nsentence: <text>\\ntopic: <detected topic>\\n```\\n\\nMake each example slightly more complex than the last, while ensuring diversity. Here is the description of the model we want to train: `{prompt}`\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    if len(prev_examples) > 0:\n",
        "        if len(prev_examples) > 8:\n",
        "            prev_examples = random.sample(prev_examples, 8)\n",
        "        for example in prev_examples:\n",
        "            messages.append({\n",
        "                \"role\": \"assistant\",\n",
        "                \"content\": example\n",
        "            })\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=messages,\n",
        "        temperature=temperature,\n",
        "        max_tokens=1000,\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message['content']\n",
        "\n",
        "# Generate examples\n",
        "prev_examples = []\n",
        "for i in range(number_of_examples):\n",
        "    print(f'Generating example {i}')\n",
        "    example = generate_example(prompt, prev_examples, temperature)\n",
        "    prev_examples.append(example)\n",
        "\n",
        "print(prev_examples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vzanco-u6ogw",
        "outputId": "68b200fe-46ee-49fa-cbf8-77a48e272cf6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating example 0\n",
            "Generating example 1\n",
            "Generating example 2\n",
            "Generating example 3\n",
            "Generating example 4\n",
            "Generating example 5\n",
            "Generating example 6\n",
            "Generating example 7\n",
            "Generating example 8\n",
            "Generating example 9\n",
            "Generating example 10\n",
            "Generating example 11\n",
            "Generating example 12\n",
            "Generating example 13\n",
            "Generating example 14\n",
            "Generating example 15\n",
            "Generating example 16\n",
            "Generating example 17\n",
            "Generating example 18\n",
            "Generating example 19\n",
            "Generating example 20\n",
            "Generating example 21\n",
            "Generating example 22\n",
            "Generating example 23\n",
            "Generating example 24\n",
            "Generating example 25\n",
            "Generating example 26\n",
            "Generating example 27\n",
            "Generating example 28\n",
            "Generating example 29\n",
            "Generating example 30\n",
            "Generating example 31\n",
            "Generating example 32\n",
            "Generating example 33\n",
            "Generating example 34\n",
            "Generating example 35\n",
            "Generating example 36\n",
            "Generating example 37\n",
            "Generating example 38\n",
            "Generating example 39\n",
            "Generating example 40\n",
            "Generating example 41\n",
            "Generating example 42\n",
            "Generating example 43\n",
            "Generating example 44\n",
            "Generating example 45\n",
            "Generating example 46\n",
            "Generating example 47\n",
            "Generating example 48\n",
            "Generating example 49\n",
            "Generating example 50\n",
            "Generating example 51\n",
            "Generating example 52\n",
            "Generating example 53\n",
            "Generating example 54\n",
            "Generating example 55\n",
            "Generating example 56\n",
            "Generating example 57\n",
            "Generating example 58\n",
            "Generating example 59\n",
            "Generating example 60\n",
            "Generating example 61\n",
            "Generating example 62\n",
            "Generating example 63\n",
            "Generating example 64\n",
            "Generating example 65\n",
            "Generating example 66\n",
            "Generating example 67\n",
            "Generating example 68\n",
            "Generating example 69\n",
            "Generating example 70\n",
            "Generating example 71\n",
            "Generating example 72\n",
            "Generating example 73\n",
            "Generating example 74\n",
            "Generating example 75\n",
            "Generating example 76\n",
            "Generating example 77\n",
            "Generating example 78\n",
            "Generating example 79\n",
            "Generating example 80\n",
            "Generating example 81\n",
            "Generating example 82\n",
            "Generating example 83\n",
            "Generating example 84\n",
            "Generating example 85\n",
            "Generating example 86\n",
            "Generating example 87\n",
            "Generating example 88\n",
            "Generating example 89\n",
            "Generating example 90\n",
            "Generating example 91\n",
            "Generating example 92\n",
            "Generating example 93\n",
            "Generating example 94\n",
            "Generating example 95\n",
            "Generating example 96\n",
            "Generating example 97\n",
            "Generating example 98\n",
            "Generating example 99\n",
            "['sentence: I love playing football on weekends.\\ntopic: Sports', 'sentence: The stock market is expected to rise next week.\\ntopic: Finance', 'sentence: The climate change is affecting the polar ice caps.\\ntopic: Environment', 'sentence: The latest iPhone model has an improved camera and longer battery life.\\ntopic: Technology', 'sentence: The new Italian restaurant downtown has the best pasta.\\ntopic: Food and Dining', 'sentence: The Mona Lisa is a masterpiece of the Italian Renaissance.\\ntopic: Art History', 'sentence: The doctor prescribed me antibiotics for my infection.\\ntopic: Health and Medicine', 'sentence: The new Tesla model has impressive acceleration and range.\\ntopic: Automobiles and Electric Vehicles', 'sentence: The global pandemic has significantly affected the travel industry.\\ntopic: Travel and COVID-19 Impact', 'sentence: The latest Marvel movie has broken box office records.\\ntopic: Entertainment and Movies', 'sentence: Climate change is causing polar ice caps to melt at an alarming rate.\\ntopic: Environmental Issues', 'sentence: The government has announced new measures to tackle unemployment.\\ntopic: Politics and Government', 'sentence: The Mediterranean diet is considered one of the healthiest in the world.\\ntopic: Nutrition and Health', 'sentence: The new diet trend involves intermittent fasting and low carb intake.\\ntopic: Health and Wellness', 'sentence: The election results will be announced tomorrow.\\ntopic: Politics and Elections', 'sentence: The stock market has been volatile due to the recent economic downturn.\\ntopic: Finance and Economy', 'sentence: The latest Avengers movie broke box office records.\\ntopic: Entertainment and Movies', 'sentence: The recent archaeological discovery in Egypt sheds light on ancient civilizations.\\ntopic: Archaeology and Ancient History', 'sentence: The latest Apple iPhone features an advanced facial recognition system.\\ntopic: Technology and Gadgets', 'sentence: The stock market crashed due to the sudden outbreak of the pandemic.\\ntopic: Finance and Economy', 'sentence: The new iPhone model features a more advanced camera system.\\ntopic: Technology and Gadgets', 'sentence: The stock market crash has led to a global economic downturn.\\ntopic: Economy and Finance', 'sentence: The new horror movie has received rave reviews for its unique plot.\\ntopic: Film and Cinema', 'sentence: The recent climate change conference discussed the importance of renewable energy sources.\\ntopic: Environment and Climate Change', 'sentence: The new iPhone model features an advanced camera system and longer battery life.\\ntopic: Technology and Gadgets', 'sentence: The climate change is causing a rise in sea levels.\\ntopic: Environment and Climate Change', 'sentence: The recent climate change conference emphasized the importance of renewable energy sources.\\ntopic: Environment and Climate Change', 'sentence: The latest iPhone model features an advanced camera system and a faster chip.\\ntopic: Technology and Gadgets', 'sentence: The recent archaeological discovery in Egypt reveals new insights into ancient civilization.\\ntopic: Archaeology and History', 'sentence: The latest iPhone model has an improved camera and longer battery life.\\ntopic: Technology and Smartphones', 'sentence: The chef prepared a delicious meal of steak and mashed potatoes.\\ntopic: Cooking and Cuisine', \"sentence: The chef's secret to a delicious pasta sauce is using fresh tomatoes.\\ntopic: Cooking and Recipes\", 'sentence: The stock market has been fluctuating due to recent political events.\\ntopic: Finance and Economy', 'sentence: The recent climate conference in Paris discussed the urgent need for countries to reduce their carbon emissions.\\ntopic: Environment and Climate Change', 'sentence: The recent advancements in artificial intelligence have greatly improved the efficiency of many industries.\\ntopic: Technology and Artificial Intelligence', \"sentence: The recent updates in the iOS software have improved the phone's performance.\\ntopic: Technology and Software Updates\", 'sentence: The new Marvel movie has broken box office records.\\ntopic: Movies and Entertainment', 'sentence: The new iPhone model features a larger screen and improved camera.\\ntopic: Technology and Gadgets', 'sentence: The new Tesla model features an impressive self-driving capability.\\ntopic: Automotive Technology', 'sentence: The Mars Rover sent back fascinating images of the Martian surface.\\ntopic: Space Exploration', 'sentence: The new art exhibition at the museum showcases contemporary artists.\\ntopic: Art and Culture', \"sentence: The recent archaeological dig in Egypt has uncovered a previously unknown pharaoh's tomb.\\ntopic: Archaeology and Ancient History\", 'sentence: The latest novel by Stephen King is a gripping tale of suspense and mystery.\\ntopic: Literature and Books', 'sentence: The stock market crashed today due to the announcement of a new trade war.\\ntopic: Finance and Economy', 'sentence: The new Tesla model offers a longer driving range and faster charging.\\ntopic: Electric Vehicles and Technology', 'sentence: The new iPhone model comes with advanced features and improved battery life.\\ntopic: Technology and Gadgets', 'sentence: The doctor recommended a balanced diet and regular exercise to maintain good health.\\ntopic: Health and Fitness', 'sentence: The stock market has been volatile due to the recent political events.\\ntopic: Finance and Economy', 'sentence: Global warming is a serious issue that needs immediate attention.\\ntopic: Environment and Climate Change', 'sentence: The climate change conference in Paris reached a significant agreement on reducing carbon emissions.\\ntopic: Environmental Issues and Climate Change', 'sentence: The stock market crashed due to the recent economic downturn.\\ntopic: Finance and Economy', 'sentence: The stock market is expected to rise due to recent developments in the tech industry.\\ntopic: Finance and Economy', 'sentence: The new Italian restaurant downtown offers a wide variety of pasta dishes.\\ntopic: Food and Dining', 'sentence: The stock market experienced a significant dip today due to fears of a potential recession.\\ntopic: Finance and Economy', 'sentence: The iPhone 13 comes with a new A15 Bionic chip, enhancing its performance.\\ntopic: Technology and Mobile Devices', 'sentence: The recent climate change conference highlighted the need for more sustainable practices.\\ntopic: Environment and Climate Change', 'sentence: The latest research on cancer treatment shows promising results with immunotherapy.\\ntopic: Health and Medicine', 'sentence: The new iPhone model features an advanced camera system and longer battery life.\\ntopic: Technology and Gadgets', 'sentence: The stock market experienced a significant drop yesterday.\\ntopic: Finance and Economy', 'sentence: The new vegan restaurant downtown offers a variety of plant-based dishes.\\ntopic: Food and Dining', 'sentence: The recent climate change conference discussed the urgent need for reducing carbon emissions.\\ntopic: Environment and Climate Change', 'sentence: The new Tesla model features an improved autopilot system.\\ntopic: Automotive Technology', \"sentence: The recent archaeological dig in Egypt uncovered a previously unknown pharaoh's tomb.\\ntopic: Archaeology and History\", 'sentence: The recent climate change conference focused on the urgent need for global cooperation.\\ntopic: Environment and Climate Change', 'sentence: The new vegan restaurant downtown offers a wide range of plant-based dishes.\\ntopic: Food and Dining', 'sentence: The new art exhibition at the local museum showcases works from the Impressionist era.\\ntopic: Art and Culture', 'sentence: The stock market experienced a significant drop today due to economic uncertainty.\\ntopic: Finance and Economy', 'sentence: The recent archaeological discovery sheds new light on ancient Egyptian civilization.\\ntopic: History and Archaeology', 'sentence: The recent archaeological discovery in Egypt has revealed new insights into Ancient Egyptian civilization.\\ntopic: History and Archaeology', 'sentence: The researchers have made a breakthrough in cancer treatment, increasing the survival rate by 20%.\\ntopic: Medical Research and Health Care', 'sentence: The new Netflix series is a thrilling crime drama set in the 1920s.\\ntopic: Entertainment and Television Shows', 'sentence: The newly discovered exoplanet could potentially support life, according to NASA scientists.\\ntopic: Space Exploration and Astronomy', 'sentence: The stock market has been particularly volatile this week due to geopolitical tensions.\\ntopic: Finance and Economy', 'sentence: The recent advances in AI technology are truly impressive.\\ntopic: Technology and Artificial Intelligence', 'sentence: The Lakers won their last game thanks to an impressive performance from LeBron James.\\ntopic: Sports and Basketball', 'sentence: The new iPhone model features an improved camera and longer battery life.\\ntopic: Technology and Gadgets', 'sentence: The recent stock market crash has led to a significant decrease in investor confidence.\\ntopic: Finance and Stock Market', 'sentence: The stock market experienced a significant drop due to recent trade disputes.\\ntopic: Finance and Economy', 'sentence: The recent political scandal has led to a public outcry for transparency and accountability.\\ntopic: Politics and Governance', 'sentence: The recent climate change conference discussed strategies for reducing greenhouse gas emissions.\\ntopic: Environment and Climate Change', 'sentence: The recent discovery of a new exoplanet has excited the scientific community.\\ntopic: Astronomy and Space Exploration', 'sentence: The latest Marvel movie has broken box office records.\\ntopic: Movies and Entertainment', 'sentence: The stock market took a significant hit due to the recent political instability.\\ntopic: Finance and Economy', 'sentence: The new Tesla model has impressive features like autopilot and increased battery life.\\ntopic: Technology and Electric Vehicles', 'sentence: The new art exhibit at the museum showcases the work of contemporary artists.\\ntopic: Art and Culture', 'sentence: The recent advancements in AI technology have revolutionized the healthcare industry.\\ntopic: Technology and Healthcare', 'sentence: The recent archaeological discovery in Egypt has shed new light on ancient civilizations.\\ntopic: History and Archaeology', 'sentence: The new vegan restaurant in town offers a variety of plant-based dishes.\\ntopic: Food and Dining', 'sentence: The new iPhone model features a larger display and improved camera quality.\\ntopic: Technology and Gadgets', 'sentence: The recent advancements in artificial intelligence have opened up new possibilities in healthcare.\\ntopic: Artificial Intelligence in Healthcare', 'sentence: The latest iPhone model features a more advanced camera and longer battery life.\\ntopic: Technology and Gadgets', 'sentence: The new Harry Potter book offers a different perspective on the magical world.\\ntopic: Literature and Fantasy Fiction', 'sentence: The researchers have made a significant breakthrough in cancer treatment.\\ntopic: Medical and Health Research', 'sentence: The latest novel by Stephen King is a thrilling horror story that keeps you on the edge of your seat.\\ntopic: Literature and Books', 'sentence: The new iPhone model features a higher resolution camera and improved battery life.\\ntopic: Technology and Gadgets', 'sentence: The recent archaeological dig has unearthed artifacts dating back to the Bronze Age.\\ntopic: History and Archaeology', 'sentence: The ongoing climate change is causing severe impact on the polar ice caps.\\ntopic: Environment and Climate Change', 'sentence: The stock market crash has led to a global financial crisis.\\ntopic: Finance and Economy', 'sentence: The new therapy technique has shown promising results in treating anxiety disorders.\\ntopic: Psychology and Mental Health', 'sentence: The climate change conference discussed innovative solutions to reduce carbon emissions.\\ntopic: Environmental Issues']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generating system message**"
      ],
      "metadata": {
        "id": "OWtutbpC845h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_system_message(prompt):\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "          {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You will be given a high-level description of the model we are training, and from that, you will generate a simple system prompt for that model to use for topic detection inference. Remember, you are not generating the system message for data generation -- you are generating the system message to use for detecting the topic of a given sentence or text. A good format to follow is: `Given a text, the model will detect the main topic.`\\n\\nMake it concise. Only include the system prompt for inference in your response.\"\n",
        "          },\n",
        "          {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": prompt.strip(),\n",
        "          }\n",
        "        ],\n",
        "        temperature=temperature,\n",
        "        max_tokens=500,\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message['content']\n",
        "\n",
        "# Your high-level model description\n",
        "prompt = \"A model that takes in a sentence or a paragraph in English and responds with the detected topic.\"\n",
        "\n",
        "# Generate the system message based on the above prompt\n",
        "system_message = generate_system_message(prompt)\n",
        "\n",
        "print(f'The system message is: `{system_message}`.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuGiX-Ks88mZ",
        "outputId": "d8541860-c6cf-4902-e28e-e760223dc242"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The system message is: `Given a sentence or paragraph in English, the model will identify and return the main topic.`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pairing the dataset**"
      ],
      "metadata": {
        "id": "ZR670AU599Ig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompts = []\n",
        "responses = []\n",
        "\n",
        "for example in prev_examples:\n",
        "    try:\n",
        "        # Split each generated example into sentence and topic\n",
        "        split_example = example.split('\\n')\n",
        "        sentence = split_example[0].replace(\"sentence:\", \"\").strip()\n",
        "        topic = split_example[1].replace(\"topic:\", \"\").strip()\n",
        "        prompts.append(sentence)\n",
        "        responses.append(topic)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "#Create a DataFrame from the examples\n",
        "df = pd.DataFrame({\n",
        "    'sentence': prompts,\n",
        "    'topic': responses\n",
        "})\n",
        "\n",
        "#Remove duplicates if any\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "print(f'There are {len(df)} successfully-generated examples.')\n",
        "\n",
        "#Prepare the training examples for fine-tuning GPT-3.5/GPT-4\n",
        "training_examples = []\n",
        "\n",
        "# Step 9: Create training examples in the format required for OpenAI fine-tuning\n",
        "for index, row in df.iterrows():\n",
        "    training_example = {\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": system_message.strip()},\n",
        "            {\"role\": \"user\", \"content\": row['sentence']},\n",
        "            {\"role\": \"assistant\", \"content\": row['topic']}\n",
        "        ]\n",
        "    }\n",
        "    training_examples.append(training_example)\n",
        "\n",
        "#Save the examples to a .jsonl file\n",
        "with open('topic_detection_training_dataset.jsonl', 'w') as f:\n",
        "    for example in training_examples:\n",
        "        f.write(json.dumps(example) + '\\n')\n",
        "\n",
        "print(\"Training examples saved to 'topic_detection_training_dataset.jsonl'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrwQFThl-AV_",
        "outputId": "c7bbcba6-7dfc-4b4c-f180-a0db2574d266"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 99 successfully-generated examples.\n",
            "Training examples saved to 'topic_detection_training_dataset.jsonl'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Upload the file to OpenAI**"
      ],
      "metadata": {
        "id": "ekNJlLUs-4NB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_id = openai.File.create(\n",
        "  file=open(\"/content/topic_detection_training_dataset.jsonl\", \"rb\"),\n",
        "  purpose='fine-tune'\n",
        ").id"
      ],
      "metadata": {
        "id": "ede_pOkj-69P"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "5srhWK5cETAX",
        "outputId": "6e404fa8-3d19-42e0-ad0c-1fe27c604bff"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'file-1eBbayqryMY4F7EWYT9BrQR7'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model training**"
      ],
      "metadata": {
        "id": "JQC4Wbtf_Rnl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "job = openai.FineTuningJob.create(training_file=file_id, model=\"gpt-3.5-turbo\")\n",
        "job_id = job.id"
      ],
      "metadata": {
        "id": "vZuzujN2_L8C"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai.FineTuningJob.list_events(id=job_id, limit=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqKWGD6i_ZmY",
        "outputId": "cf56c02f-aa4e-4669-ff50-de1721331411"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject list at 0x7846f49b8ea0> JSON: {\n",
              "  \"object\": \"list\",\n",
              "  \"data\": [\n",
              "    {\n",
              "      \"object\": \"fine_tuning.job.event\",\n",
              "      \"id\": \"ftevent-gwLVGmUrUI9GHPSLCOZyjym9\",\n",
              "      \"created_at\": 1727417251,\n",
              "      \"level\": \"info\",\n",
              "      \"message\": \"Step 40/297: training loss=0.67\",\n",
              "      \"data\": {\n",
              "        \"step\": 40,\n",
              "        \"train_loss\": 0.6701720356941223,\n",
              "        \"total_steps\": 297,\n",
              "        \"train_mean_token_accuracy\": 0.7142857313156128\n",
              "      },\n",
              "      \"type\": \"metrics\"\n",
              "    },\n",
              "    {\n",
              "      \"object\": \"fine_tuning.job.event\",\n",
              "      \"id\": \"ftevent-3RTyYXosnLoydIvEBjU85pdq\",\n",
              "      \"created_at\": 1727417248,\n",
              "      \"level\": \"info\",\n",
              "      \"message\": \"Step 39/297: training loss=1.10\",\n",
              "      \"data\": {\n",
              "        \"step\": 39,\n",
              "        \"train_loss\": 1.0960127115249634,\n",
              "        \"total_steps\": 297,\n",
              "        \"train_mean_token_accuracy\": 0.7142857313156128\n",
              "      },\n",
              "      \"type\": \"metrics\"\n",
              "    },\n",
              "    {\n",
              "      \"object\": \"fine_tuning.job.event\",\n",
              "      \"id\": \"ftevent-OfMSgtB7qBv34Acl1wonvKyA\",\n",
              "      \"created_at\": 1727417248,\n",
              "      \"level\": \"info\",\n",
              "      \"message\": \"Step 38/297: training loss=0.06\",\n",
              "      \"data\": {\n",
              "        \"step\": 38,\n",
              "        \"train_loss\": 0.057706069201231,\n",
              "        \"total_steps\": 297,\n",
              "        \"train_mean_token_accuracy\": 1.0\n",
              "      },\n",
              "      \"type\": \"metrics\"\n",
              "    },\n",
              "    {\n",
              "      \"object\": \"fine_tuning.job.event\",\n",
              "      \"id\": \"ftevent-9kef8mFel9ylu0wpDpF4Z2em\",\n",
              "      \"created_at\": 1727417244,\n",
              "      \"level\": \"info\",\n",
              "      \"message\": \"Step 37/297: training loss=0.00\",\n",
              "      \"data\": {\n",
              "        \"step\": 37,\n",
              "        \"train_loss\": 0.0020306904334574938,\n",
              "        \"total_steps\": 297,\n",
              "        \"train_mean_token_accuracy\": 1.0\n",
              "      },\n",
              "      \"type\": \"metrics\"\n",
              "    },\n",
              "    {\n",
              "      \"object\": \"fine_tuning.job.event\",\n",
              "      \"id\": \"ftevent-aMKkloC6vwqHscqI7Krh45Hl\",\n",
              "      \"created_at\": 1727417244,\n",
              "      \"level\": \"info\",\n",
              "      \"message\": \"Step 36/297: training loss=0.06\",\n",
              "      \"data\": {\n",
              "        \"step\": 36,\n",
              "        \"train_loss\": 0.05522696301341057,\n",
              "        \"total_steps\": 297,\n",
              "        \"train_mean_token_accuracy\": 1.0\n",
              "      },\n",
              "      \"type\": \"metrics\"\n",
              "    },\n",
              "    {\n",
              "      \"object\": \"fine_tuning.job.event\",\n",
              "      \"id\": \"ftevent-jIMnUdT3Y6gUB6GsibVAKNEd\",\n",
              "      \"created_at\": 1727417243,\n",
              "      \"level\": \"info\",\n",
              "      \"message\": \"Step 35/297: training loss=0.00\",\n",
              "      \"data\": {\n",
              "        \"step\": 35,\n",
              "        \"train_loss\": 0.003755251644179225,\n",
              "        \"total_steps\": 297,\n",
              "        \"train_mean_token_accuracy\": 1.0\n",
              "      },\n",
              "      \"type\": \"metrics\"\n",
              "    },\n",
              "    {\n",
              "      \"object\": \"fine_tuning.job.event\",\n",
              "      \"id\": \"ftevent-IALoMKjEx6qGI0sU6inwZ3lU\",\n",
              "      \"created_at\": 1727417240,\n",
              "      \"level\": \"info\",\n",
              "      \"message\": \"Step 34/297: training loss=0.28\",\n",
              "      \"data\": {\n",
              "        \"step\": 34,\n",
              "        \"train_loss\": 0.27553239464759827,\n",
              "        \"total_steps\": 297,\n",
              "        \"train_mean_token_accuracy\": 0.8333333134651184\n",
              "      },\n",
              "      \"type\": \"metrics\"\n",
              "    },\n",
              "    {\n",
              "      \"object\": \"fine_tuning.job.event\",\n",
              "      \"id\": \"ftevent-ZcS6CdzwVmrRl5RnAG9FzahO\",\n",
              "      \"created_at\": 1727417240,\n",
              "      \"level\": \"info\",\n",
              "      \"message\": \"Step 33/297: training loss=0.28\",\n",
              "      \"data\": {\n",
              "        \"step\": 33,\n",
              "        \"train_loss\": 0.280958890914917,\n",
              "        \"total_steps\": 297,\n",
              "        \"train_mean_token_accuracy\": 0.875\n",
              "      },\n",
              "      \"type\": \"metrics\"\n",
              "    },\n",
              "    {\n",
              "      \"object\": \"fine_tuning.job.event\",\n",
              "      \"id\": \"ftevent-bNtqhro30hpcDTfmroZpqizL\",\n",
              "      \"created_at\": 1727417240,\n",
              "      \"level\": \"info\",\n",
              "      \"message\": \"Step 32/297: training loss=1.56\",\n",
              "      \"data\": {\n",
              "        \"step\": 32,\n",
              "        \"train_loss\": 1.5649995803833008,\n",
              "        \"total_steps\": 297,\n",
              "        \"train_mean_token_accuracy\": 0.6666666865348816\n",
              "      },\n",
              "      \"type\": \"metrics\"\n",
              "    },\n",
              "    {\n",
              "      \"object\": \"fine_tuning.job.event\",\n",
              "      \"id\": \"ftevent-OL9C0gAQGFY0lqY9Hrj8AFYI\",\n",
              "      \"created_at\": 1727417236,\n",
              "      \"level\": \"info\",\n",
              "      \"message\": \"Step 31/297: training loss=0.01\",\n",
              "      \"data\": {\n",
              "        \"step\": 31,\n",
              "        \"train_loss\": 0.014475250616669655,\n",
              "        \"total_steps\": 297,\n",
              "        \"train_mean_token_accuracy\": 1.0\n",
              "      },\n",
              "      \"type\": \"metrics\"\n",
              "    }\n",
              "  ],\n",
              "  \"has_more\": true\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "job_details = openai.FineTuningJob.retrieve(job_id)\n",
        "print(job_details.status)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrpAZyz2FrjV",
        "outputId": "fad16bc1-19eb-48d9-b948-31d045285a8d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "while True:\n",
        "    job_details = openai.FineTuningJob.retrieve(job_id)\n",
        "    status = job_details.status\n",
        "    print(status)\n",
        "    if status in [\"succeeded\", \"failed\"]:\n",
        "        break\n",
        "    time.sleep(30)  # Wait for 30 seconds before checking again\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fs1OleVGITH",
        "outputId": "3bc8616e-fdb8-42c4-c242-b7413a32ecf4"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running\n",
            "running\n",
            "running\n",
            "running\n",
            "running\n",
            "running\n",
            "running\n",
            "running\n",
            "running\n",
            "running\n",
            "running\n",
            "running\n",
            "running\n",
            "running\n",
            "succeeded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name_pre_object = openai.FineTuningJob.retrieve(job_id)\n",
        "model_name = model_name_pre_object.fine_tuned_model\n",
        "print(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVnhMmsB_hlE",
        "outputId": "33f72936-eccc-4270-80bc-5254fc5f1df1"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ft:gpt-3.5-turbo-0125:iterate-ai::AByY28et\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.ChatCompletion.create(\n",
        "    model=model_name,\n",
        "    messages=[\n",
        "      {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": system_message,\n",
        "      },\n",
        "      {\n",
        "          \"role\": \"user\",\n",
        "          \"content\": df['sentence'].sample().values[0],\n",
        "      }\n",
        "    ],\n",
        ")\n",
        "\n",
        "response.choices[0].message['content']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "028Ake00_rbs",
        "outputId": "f0d146e2-f606-47cb-e7fb-53a260652fe5"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Archaeology'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_cases = [\n",
        "    \"The new horror movie has received rave reviews for its unique plot.\",\n",
        "    \"New policies are being implemented to address climate change.\",\n",
        "    \"A recent study shows the impact of plastic on marine life.\",\n",
        "    \"Advancements in renewable energy technologies are promising.\"\n",
        "]\n",
        "\n",
        "for case in test_cases:\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model_name,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": system_message,\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": case,\n",
        "            }\n",
        "        ],\n",
        "    )\n",
        "    topic = response.choices[0].message['content']\n",
        "    print(f\"User Message: {case}\")\n",
        "    print(f\"Predicted Topic: {topic}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbWzinNcJfD2",
        "outputId": "bef1d78a-3fbf-45b8-f72c-7add13b1e9a9"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User Message: The new horror movie has received rave reviews for its unique plot.\n",
            "Predicted Topic: Movies\n",
            "\n",
            "User Message: New policies are being implemented to address climate change.\n",
            "Predicted Topic: Environment\n",
            "\n",
            "User Message: A recent study shows the impact of plastic on marine life.\n",
            "Predicted Topic: Environment\n",
            "\n",
            "User Message: Advancements in renewable energy technologies are promising.\n",
            "Predicted Topic: Environment and Energy\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KBHQeiLn_w7K"
      },
      "execution_count": 39,
      "outputs": []
    }
  ]
}